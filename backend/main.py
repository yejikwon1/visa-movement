from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
import os
from dotenv import load_dotenv
import requests

# âœ… include route import
from should_include import app as include_app

# í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸° (.env)
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_URL = "https://api.openai.com/v1/chat/completions"

# FastAPI ì•± ì •ì˜
app = FastAPI()

# â­ï¸ CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# âœ… /chat ì—”ë“œí¬ì¸íŠ¸
@app.post("/chat")
async def chat(request: Request):
    body = await request.json()
    messages = body.get("messages", [])

    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }

    payload = {
        "model": "gpt-3.5-turbo",
        "messages": messages
    }

    response = requests.post(OPENAI_URL, headers=headers, json=payload)
    result = response.json()

    # âœ… usage ë¡œê·¸
    usage = result.get("usage", {})
    prompt_tokens = usage.get("prompt_tokens", 0)
    completion_tokens = usage.get("completion_tokens", 0)
    total_tokens = usage.get("total_tokens", 0)
    cost = (prompt_tokens / 1000 * 0.0015) + (completion_tokens / 1000 * 0.002)  # gpt-3.5-turbo ê¸°ì¤€
    print(f"ğŸ“Š [OpenAI Usage] Prompt: {prompt_tokens}, Completion: {completion_tokens}, Total: {total_tokens}, ğŸ’µ Estimated Cost: ${cost:.6f}")

    return result

# âœ… /shouldIncludeVisaData ê²½ë¡œ mount (ë³„ë„ ì•± í†µí•©)
app.mount("/shouldIncludeVisaData", include_app)
